{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39445abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39634f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "artificial intelligence is transforming modern society.\n",
    "it is used in healthcare finance education and transportation.\n",
    "machine learning allows systems to improve automatically with experience.\n",
    "data plays a critical role in training intelligent systems.\n",
    "large datasets help models learn complex patterns.\n",
    "deep learning uses multi layer neural networks.\n",
    "neural networks are inspired by biological neurons.\n",
    "each neuron processes input and produces an output.\n",
    "training a neural network requires optimization techniques.\n",
    "gradient descent minimizes the loss function.\n",
    "\n",
    "natural language processing helps computers understand human language.\n",
    "text generation is a key task in nlp.\n",
    "language models predict the next word or character.\n",
    "recurrent neural networks handle sequential data.\n",
    "lstm and gru models address long term dependency problems.\n",
    "however rnn based models are slow for long sequences.\n",
    "\n",
    "transformer models changed the field of nlp.\n",
    "they rely on self attention mechanisms.\n",
    "attention allows the model to focus on relevant context.\n",
    "transformers process data in parallel.\n",
    "this makes training faster and more efficient.\n",
    "modern language models are based on transformers.\n",
    "\n",
    "education is being improved using artificial intelligence.\n",
    "intelligent tutoring systems personalize learning.\n",
    "automated grading saves time for teachers.\n",
    "online education platforms use recommendation systems.\n",
    "technology enhances the quality of learning experiences.\n",
    "\n",
    "ethical considerations are important in artificial intelligence.\n",
    "fairness transparency and accountability must be ensured.\n",
    "ai systems should be designed responsibly.\n",
    "data privacy and security are major concerns.\n",
    "researchers continue to improve ai safety.\n",
    "\n",
    "text generation models can create stories poems and articles.\n",
    "they are used in chatbots virtual assistants and content creation.\n",
    "generated text should be meaningful and coherent.\n",
    "evaluation of text generation is challenging.\n",
    "human judgement is often required.\n",
    "\n",
    "continuous learning is essential in the field of ai.\n",
    "research and innovation drive technological progress.\n",
    "students should build strong foundations in mathematics.\n",
    "programming skills are important for ai engineers.\n",
    "practical experimentation enhances understanding.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27f5c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    chars = sorted(list(set(text)))\n",
    "    \n",
    "    char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
    "    idx_to_char = {i:ch for i,ch in enumerate(chars)}\n",
    "    \n",
    "    encoded = [char_to_idx[ch] for ch in text]\n",
    "    \n",
    "    return encoded, char_to_idx, idx_to_char, len(chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4718f666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(encoded_text, seq_length):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(len(encoded_text) - seq_length):\n",
    "        inputs.append(encoded_text[i:i+seq_length])\n",
    "        targets.append(encoded_text[i+seq_length])\n",
    "        \n",
    "    return inputs, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c345bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(ScratchGRU, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        \n",
    "        # Gates\n",
    "        self.Wz = nn.Linear(hidden_size + hidden_size, hidden_size)\n",
    "        self.Wr = nn.Linear(hidden_size + hidden_size, hidden_size)\n",
    "        self.Wh = nn.Linear(hidden_size + hidden_size, hidden_size)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.size()\n",
    "        \n",
    "        h = torch.zeros(batch_size, self.hidden_size)\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            x_embed = self.embedding(x[:, t])\n",
    "            \n",
    "            combined = torch.cat((h, x_embed), dim=1)\n",
    "            \n",
    "            z = torch.sigmoid(self.Wz(combined))\n",
    "            r = torch.sigmoid(self.Wr(combined))\n",
    "            \n",
    "            combined_reset = torch.cat((r * h, x_embed), dim=1)\n",
    "            h_tilde = torch.tanh(self.Wh(combined_reset))\n",
    "            \n",
    "            h = (1 - z) * h + z * h_tilde\n",
    "        \n",
    "        output = self.fc(h)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9036af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded, char_to_idx, idx_to_char, vocab_size = preprocess_text(text)\n",
    "\n",
    "seq_length = 40\n",
    "inputs, targets = create_sequences(encoded, seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "152f433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "model = ScratchGRU(vocab_size, hidden_size)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2796e1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.7124\n",
      "Epoch 2, Loss: 2.3335\n",
      "Epoch 3, Loss: 2.1649\n",
      "Epoch 4, Loss: 2.0396\n",
      "Epoch 5, Loss: 1.8988\n",
      "Epoch 6, Loss: 1.8519\n",
      "Epoch 7, Loss: 1.7310\n",
      "Epoch 8, Loss: 1.6720\n",
      "Epoch 9, Loss: 1.6577\n",
      "Epoch 10, Loss: 1.5936\n",
      "Epoch 11, Loss: 1.5231\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([targets[i]])\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 11\u001b[0m output \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, y)\n\u001b[0;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\shiva\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\shiva\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[5], line 26\u001b[0m, in \u001b[0;36mScratchGRU.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m x_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x[:, t])\n\u001b[0;32m     24\u001b[0m combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((h, x_embed), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWz(combined))\n\u001b[0;32m     27\u001b[0m r \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWr(combined))\n\u001b[0;32m     29\u001b[0m combined_reset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((r \u001b[38;5;241m*\u001b[39m h, x_embed), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\shiva\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\shiva\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\shiva\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        x = torch.tensor([inputs[i]])\n",
    "        y = torch.tensor([targets[i]])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(inputs):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bac7159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, seed_text, seq_length, char_to_idx, idx_to_char, length=200):\n",
    "    \n",
    "    model.eval()\n",
    "    generated = seed_text\n",
    "    \n",
    "    for _ in range(length):\n",
    "        input_seq = generated[-seq_length:]\n",
    "        input_indices = [char_to_idx[ch] for ch in input_seq]\n",
    "        input_tensor = torch.tensor([input_indices])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            prob = torch.softmax(output, dim=1)\n",
    "            predicted_idx = torch.argmax(prob).item()\n",
    "        \n",
    "        generated += idx_to_char[predicted_idx]\n",
    "    \n",
    "    return generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f9603ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial intelligence enting.\n",
      "aution sk usivn enhand\n"
     ]
    }
   ],
   "source": [
    "seed = \"artificial intelligence \"\n",
    "print(generate_text(model, seed, seq_length, char_to_idx, idx_to_char, 30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4c9f3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106141\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6d78cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ScratchGRU                               [1, 29]                   --\n",
       "├─Embedding: 1-1                         [1, 128]                  3,712\n",
       "├─Linear: 1-2                            [1, 128]                  32,896\n",
       "├─Linear: 1-3                            [1, 128]                  32,896\n",
       "├─Linear: 1-4                            [1, 128]                  32,896\n",
       "├─Embedding: 1-5                         [1, 128]                  (recursive)\n",
       "├─Linear: 1-6                            [1, 128]                  (recursive)\n",
       "├─Linear: 1-7                            [1, 128]                  (recursive)\n",
       "├─Linear: 1-8                            [1, 128]                  (recursive)\n",
       "├─Embedding: 1-9                         [1, 128]                  (recursive)\n",
       "├─Linear: 1-10                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-11                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-12                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-13                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-14                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-15                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-16                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-17                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-18                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-19                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-20                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-21                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-22                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-23                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-24                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-25                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-26                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-27                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-28                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-29                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-30                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-31                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-32                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-33                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-34                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-35                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-36                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-37                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-38                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-39                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-40                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-41                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-42                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-43                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-44                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-45                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-46                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-47                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-48                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-49                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-50                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-51                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-52                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-53                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-54                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-55                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-56                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-57                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-58                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-59                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-60                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-61                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-62                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-63                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-64                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-65                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-66                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-67                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-68                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-69                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-70                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-71                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-72                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-73                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-74                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-75                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-76                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-77                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-78                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-79                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-80                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-81                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-82                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-83                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-84                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-85                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-86                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-87                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-88                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-89                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-90                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-91                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-92                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-93                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-94                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-95                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-96                           [1, 128]                  (recursive)\n",
       "├─Embedding: 1-97                        [1, 128]                  (recursive)\n",
       "├─Linear: 1-98                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-99                           [1, 128]                  (recursive)\n",
       "├─Linear: 1-100                          [1, 128]                  (recursive)\n",
       "├─Embedding: 1-101                       [1, 128]                  (recursive)\n",
       "├─Linear: 1-102                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-103                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-104                          [1, 128]                  (recursive)\n",
       "├─Embedding: 1-105                       [1, 128]                  (recursive)\n",
       "├─Linear: 1-106                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-107                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-108                          [1, 128]                  (recursive)\n",
       "├─Embedding: 1-109                       [1, 128]                  (recursive)\n",
       "├─Linear: 1-110                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-111                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-112                          [1, 128]                  (recursive)\n",
       "├─Embedding: 1-113                       [1, 128]                  (recursive)\n",
       "├─Linear: 1-114                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-115                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-116                          [1, 128]                  (recursive)\n",
       "├─Embedding: 1-117                       [1, 128]                  (recursive)\n",
       "├─Linear: 1-118                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-119                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-120                          [1, 128]                  (recursive)\n",
       "├─Embedding: 1-121                       [1, 128]                  (recursive)\n",
       "├─Linear: 1-122                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-123                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-124                          [1, 128]                  (recursive)\n",
       "├─Embedding: 1-125                       [1, 128]                  (recursive)\n",
       "├─Linear: 1-126                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-127                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-128                          [1, 128]                  (recursive)\n",
       "├─Embedding: 1-129                       [1, 128]                  (recursive)\n",
       "├─Linear: 1-130                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-131                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-132                          [1, 128]                  (recursive)\n",
       "├─Embedding: 1-133                       [1, 128]                  (recursive)\n",
       "├─Linear: 1-134                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-135                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-136                          [1, 128]                  (recursive)\n",
       "├─Embedding: 1-137                       [1, 128]                  (recursive)\n",
       "├─Linear: 1-138                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-139                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-140                          [1, 128]                  (recursive)\n",
       "├─Embedding: 1-141                       [1, 128]                  (recursive)\n",
       "├─Linear: 1-142                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-143                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-144                          [1, 128]                  (recursive)\n",
       "├─Embedding: 1-145                       [1, 128]                  (recursive)\n",
       "├─Linear: 1-146                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-147                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-148                          [1, 128]                  (recursive)\n",
       "├─Embedding: 1-149                       [1, 128]                  (recursive)\n",
       "├─Linear: 1-150                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-151                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-152                          [1, 128]                  (recursive)\n",
       "├─Embedding: 1-153                       [1, 128]                  (recursive)\n",
       "├─Linear: 1-154                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-155                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-156                          [1, 128]                  (recursive)\n",
       "├─Embedding: 1-157                       [1, 128]                  (recursive)\n",
       "├─Linear: 1-158                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-159                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-160                          [1, 128]                  (recursive)\n",
       "├─Linear: 1-161                          [1, 29]                   3,741\n",
       "==========================================================================================\n",
       "Total params: 106,141\n",
       "Trainable params: 106,141\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 4.10\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.16\n",
       "Params size (MB): 0.42\n",
       "Estimated Total Size (MB): 0.59\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "dummy_input = torch.randint(0, vocab_size, (1, seq_length), dtype=torch.long)\n",
    "\n",
    "summary(model, input_data=dummy_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25393bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
